{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d7d9c6-d1bf-42fe-b86c-32f6dcd557bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 30) (3315716334.py, line 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 30\u001b[1;36m\u001b[0m\n\u001b[1;33m    'self_coefficient_mask = self.params['coefficient_initialization']\u001b[0m\n\u001b[1;37m                                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 30)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import Dict\n",
    "import torch\n",
    "from SINDy_library import *\n",
    "from ..autoencoder.autoencoder import AutoEncoder\n",
    "\n",
    "class SINDy(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    SINDy dz predictions\n",
    "\n",
    "    Arguments:\n",
    "        params - Dictionary object containing the parameters that specify the training.\n",
    "        See params.txt file for a description of the parameters.\n",
    "\n",
    "    Returns:\n",
    "        sindy_predict - tensor containing sindy's predictions for dz.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, params:Dict = {}, encoder:AutoEncoder = torch.Tensor, *args, **kwargs) -> None:\n",
    "      super().__init__(*args, **kwargs) #what for?\n",
    "      self.params = params\n",
    "      self.encoder = encoder\n",
    "\n",
    "      self.input_dim = self.params['input_dim']\n",
    "      self.latent_dim = self.params['latent_dim']\n",
    "      self.poly_order = self.params['poly_order']\n",
    "      if 'include_sine' in self.params.keys():\n",
    "        self.include_sine = self.params['include_sine']\n",
    "      else:\n",
    "        self.include_sine = False\n",
    "      self.library_dim = self.params['library_dim']\n",
    "      self.model_order = self.params['model_order']\n",
    "      self.sequential_thresholding = self.params['sequential_thresholding']\n",
    "      self_coefficient_initialization = self.params['coefficient_initialization']\n",
    "      #'self_coefficient_mask = self.params['coefficient_initialization']\n",
    "\n",
    "      self.sindy_coefficients = torch.zeros((self.library_dim, self.latent_dim))\n",
    "            #initialize sindy coefficients\n",
    "      self.init_sindy_coefficients()\n",
    "\n",
    "\n",
    "    def init_sindy_coefficients(self, name='normal', std=1.):\n",
    "\n",
    "      self.sindy_coefficients = std*torch.randn_like(self.sindy_coefficients)\n",
    "\n",
    "      ''' \n",
    "      if name == 'xavier':\n",
    "        self.sindy_coefficients = torch.nn.init.xavier_uniform_(self.sindy_coefficients)\n",
    "      elif name == 'uniform':\n",
    "        self.sindy_coefficients = torch.nn.init.uniform_(self.sindy_coefficients, low=0.0, high=1.0)\n",
    "      elif name == 'normal':\n",
    "        self.sindy_coefficients = torch.nn.init.normal_(self.sindy_coefficients, mean=0, std=1) \n",
    "      '''\n",
    "      \n",
    "\n",
    "    def forward(self, x, dx, ddx)-> torch.Tensor:\n",
    "\n",
    "      z, dz, ddz = self.encoder(x,dx, ddx)\n",
    "\n",
    "      #create Theta\n",
    "      if self.model_order == 1:\n",
    "        Theta = sindy_library_tf(z, self.latent_dim, self.poly_order, self.include_sine)\n",
    "      else:\n",
    "        Theta = sindy_library_tf_order2(self.encoder.z, self.encoder.dz, self.latent_dim, self.poly_order, self.include_sine)\n",
    "      \n",
    "\n",
    "\n",
    "      #apply thresholding or not\n",
    "      if self.sequential_thresholding:\n",
    "        '''\n",
    "        tmp = torch.rand(size=(library_dim,latent_dim), dtype=torch.float32)\n",
    "        mask = torch.zeros_like(tmp)\n",
    "        mask = mask.where(self.coefficient_mask, tmp)\n",
    "        '''\n",
    "        mask = torch.rand(size=(self.library_dim, self.latent_dim), dtype=torch.float32)\n",
    "        sindy_predict = torch.matmul(Theta, mask*self.sindy_coefficients)\n",
    "      else:\n",
    "        sindy_predict = tf.matmul(Theta, sindy_coefficients)\n",
    "      \n",
    "      \n",
    "      x_decode, dx_decode, ddx_decode = self.decoder(z, dz, ddz)\n",
    "\n",
    "    return torch.cat((x, dx, z, dz, x_decode, dx_decode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06b777c-3b7e-42f0-bdb7-3ad7103b353d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sindy = SINDy()\n",
    "sindy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
